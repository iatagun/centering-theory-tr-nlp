"""
Centering Theory + Stanza JSON Format entegrasyon testi
"""
import os
os.environ['TORCH_FORCE_WEIGHTS_ONLY_LOAD'] = '0'

from api.pos_semantic_analyzer import analyze_text
import json

# Test cÃ¼mleleri
test_texts = [
    "Ali kitabÄ± okudu.",
    "Ali'nin okuduÄŸu kitap burada.",
    "KuÅŸlar uÃ§ar.",
    "Ali sabahlarÄ± erken kalkar.",
    "YÃ¼zme havuzu temiz."
]

print("=" * 100)
print("STANZA JSON FORMAT + CENTERING THEORY - Full Integration Test")
print("=" * 100)

for i, text in enumerate(test_texts, 1):
    print(f"\n{'='*100}")
    print(f"Test {i}: {text}")
    print('='*100)
    
    result = analyze_text(text)
    
    # JSON Ã§Ä±ktÄ±sÄ±
    json_output = json.dumps(result, indent=2, ensure_ascii=False)
    print(json_output)
    
    # Ã–nemli alanlarÄ± vurgula
    sent = result["sentences"][0]
    
    print(f"\n{'â”€'*100}")
    print("ðŸ“Š Ã–ZET:")
    print('â”€'*100)
    
    # Preferences
    if sent["preferences"]:
        print(f"\nâœ… PREFERENCES ({len(sent['preferences'])} kelime):")
        for pref in sent["preferences"]:
            print(f"  â€¢ {pref['word']}: {pref['stanza_pos']} â†’ {pref['suggested_pos']}")
            print(f"    Discourse: {pref['discourse_role']}, Referential: {pref['referential_status']}")
    else:
        print("\nâœ… PREFERENCES: None (Stanza doÄŸru etiketlemiÅŸ)")
    
    # Semantics - Discourse
    if sent["semantics"] and "discourse" in sent["semantics"]:
        disc = sent["semantics"]["discourse"]
        print(f"\nðŸ’¬ DISCOURSE:")
        print(f"  â€¢ Topics (Cb): {disc['topic_candidates']}")
        print(f"  â€¢ Focus (Cf): {disc['focus_entities']}")
        print(f"  â€¢ Referential density: {disc['referential_density']}")
        print(f"  â€¢ Roles: {disc['discourse_role_distribution']}")
    
    # Semantics - Information Structure
    if sent["semantics"] and "information_structure" in sent["semantics"]:
        info = sent["semantics"]["information_structure"]
        print(f"\nðŸ“‹ INFORMATION STRUCTURE:")
        print(f"  â€¢ Given: {info['given_entities']}")
        print(f"  â€¢ New: {info['new_entities']}")
        print(f"  â€¢ Topic position: {info['topic_position']}")
        print(f"  â€¢ Packaging: {info['information_packaging']}")
    
    # Semantics - Propositional
    if sent["semantics"]:
        sem = sent["semantics"]
        print(f"\nðŸ”¬ PROPOSITIONAL SEMANTICS:")
        print(f"  â€¢ Type: {sem['proposition_type']}")
        print(f"  â€¢ Predicate: {sem['predicate_type']}")
        print(f"  â€¢ Finiteness: {sem['clause_finiteness']}")
        if sem['generic_encoding']:
            print(f"  â€¢ Generic: Yes (verifiability: {sem['verifiability']})")

print(f"\n{'='*100}")
print("âœ… Entegrasyon testi tamamlandÄ±!")
print("=" * 100)

# JSON dosyasÄ±na kaydet
output_file = "centering_stanza_output.json"
final_result = {
    "test_description": "Turkish POS Semantic Analyzer with Centering Theory",
    "format": "Stanza JSON + Extensions",
    "tests": []
}

for text in test_texts:
    result = analyze_text(text)
    final_result["tests"].append(result)

with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(final_result, f, indent=2, ensure_ascii=False)

print(f"\nðŸ’¾ JSON Ã§Ä±ktÄ± kaydedildi: {output_file}")
